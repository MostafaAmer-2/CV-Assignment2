{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadTrainingSet():\n",
    "    images = np.empty([2400, 785], dtype=np.float64)\n",
    "    for i in range(1, 2401):\n",
    "        img = plt.imread('./Train/' + str(i) + '.jpg')\n",
    "        img2 = img.flatten()\n",
    "        img3 = np.append(img2, 1)\n",
    "        images[i-1] = img3\n",
    "\n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1 Perceptron\n",
    "\n",
    "Configure the initial weights for the perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configureInitialWeightMatrix():\n",
    "    weights = np.zeros([10, 784])\n",
    "    ones = np.ones([10, 1])\n",
    "    return np.hstack((ones, weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with learning rate 1.0\n",
      "Training Class 0\n",
      "Training Class 1\n",
      "Training Class 2\n",
      "Training Class 3\n",
      "Training Class 4\n",
      "Training Class 5\n",
      "Training Class 6\n",
      "Training Class 7\n",
      "Training Class 8\n",
      "Training Class 9\n",
      "Training with learning rate 0.1\n",
      "Training Class 0\n",
      "Training Class 1\n",
      "Training Class 2\n",
      "Training Class 3\n",
      "Training Class 4\n",
      "Training Class 5\n",
      "Training Class 6\n",
      "Training Class 7\n",
      "Training Class 8\n",
      "Training Class 9\n",
      "Training with learning rate 0.01\n",
      "Training Class 0\n",
      "Training Class 1\n",
      "Training Class 2\n",
      "Training Class 3\n",
      "Training Class 4\n",
      "Training Class 5\n",
      "Training Class 6\n",
      "Training Class 7\n",
      "Training Class 8\n",
      "Training Class 9\n",
      "Training with learning rate 0.001\n",
      "Training Class 0\n",
      "Training Class 1\n",
      "Training Class 2\n",
      "Training Class 3\n",
      "Training Class 4\n",
      "Training Class 5\n",
      "Training Class 6\n",
      "Training Class 7\n",
      "Training Class 8\n",
      "Training Class 9\n",
      "Training with learning rate 0.0001\n",
      "Training Class 0\n",
      "Training Class 1\n",
      "Training Class 2\n",
      "Training Class 3\n",
      "Training Class 4\n",
      "Training Class 5\n",
      "Training Class 6\n",
      "Training Class 7\n",
      "Training Class 8\n",
      "Training Class 9\n",
      "Training with learning rate 1e-05\n",
      "Training Class 0\n",
      "Training Class 1\n",
      "Training Class 2\n",
      "Training Class 3\n",
      "Training Class 4\n",
      "Training Class 5\n",
      "Training Class 6\n",
      "Training Class 7\n",
      "Training Class 8\n",
      "Training Class 9\n",
      "Training with learning rate 1e-06\n",
      "Training Class 0\n",
      "Training Class 1\n",
      "Training Class 2\n",
      "Training Class 3\n",
      "Training Class 4\n",
      "Training Class 5\n",
      "Training Class 6\n",
      "Training Class 7\n",
      "Training Class 8\n",
      "Training Class 9\n",
      "Training with learning rate 1e-07\n",
      "Training Class 0\n",
      "Training Class 1\n",
      "Training Class 2\n",
      "Training Class 3\n",
      "Training Class 4\n",
      "Training Class 5\n",
      "Training Class 6\n",
      "Training Class 7\n",
      "Training Class 8\n",
      "Training Class 9\n",
      "Training with learning rate 1e-08\n",
      "Training Class 0\n",
      "Training Class 1\n",
      "Training Class 2\n",
      "Training Class 3\n",
      "Training Class 4\n",
      "Training Class 5\n",
      "Training Class 6\n",
      "Training Class 7\n",
      "Training Class 8\n",
      "Training Class 9\n",
      "Training with learning rate 1e-09\n",
      "Training Class 0\n",
      "Training Class 1\n",
      "Training Class 2\n",
      "Training Class 3\n",
      "Training Class 4\n",
      "Training Class 5\n",
      "Training Class 6\n",
      "Training Class 7\n",
      "Training Class 8\n",
      "Training Class 9\n"
     ]
    }
   ],
   "source": [
    "images = loadTrainingSet()\n",
    "learning_rates = np.array([1.0, 0.1, 0.01, 0.001, 0.0001, 0.00001, 0.000001, 0.0000001, 0.00000001, 0.000000001])\n",
    "\n",
    "for n in learning_rates:\n",
    "    print(\"Training with learning rate \"+ str(n))\n",
    "    weights = configureInitialWeightMatrix()\n",
    "    confusionMatrix = np.zeros((10, 10))\n",
    "    for c in range(10):\n",
    "        print(\"Training Class \" + str(c))\n",
    "        # handling targets\n",
    "        startingTarget = 240 * c  # 1*0, 1*1, 1*2....etc\n",
    "        target = np.full(2400, -1)\n",
    "        target[startingTarget:startingTarget + 240] = 1\n",
    "\n",
    "        for epoch in range(500):\n",
    "            for img in range(0, 2400):\n",
    "                currentImage = images[img]\n",
    "                currentTarget = target[img]\n",
    "                calculatedTarget = 1 if (np.dot(weights[c], currentImage) >= 0) else -1\n",
    "                if (calculatedTarget != currentTarget):\n",
    "                    weights[c] = weights[c] + (n * currentImage * currentTarget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the data and generate the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix - 9\n",
      "[[20.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0. 19.  0.  0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0. 16.  0.  1.  1.  1.  0.  1.  0.]\n",
      " [ 0.  0.  1. 17.  0.  1.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0. 16.  1.  0.  0.  0.  3.]\n",
      " [ 0.  0.  1.  1.  0. 17.  0.  0.  1.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0. 18.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  2.  0.  0. 18.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.  0. 19.  0.]\n",
      " [ 0.  0.  1.  0.  0.  1.  0.  4.  0. 14.]]\n"
     ]
    }
   ],
   "source": [
    "    for i in range(1, 201):\n",
    "        testImg = plt.imread('./Test/' + str(i) + '.jpg')\n",
    "        testImg = np.append(testImg.flatten(), 1)\n",
    "        dot = np.dot(weights, testImg)\n",
    "        index = np.argmax(dot)\n",
    "        confusionMatrix[((i - 1) // 20)][index] = confusionMatrix[((i - 1) // 20)][index] + 1\n",
    "    position_n, = np.where(learning_rates == n)\n",
    "    print(\"Confusion Matrix - \" + str(position_n[0]))\n",
    "    print(confusionMatrix)\n",
    "    plt.imshow(confusionMatrix)\n",
    "    plt.savefig(\"./Confusion-\"+str(position_n[0]) +\".jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2 Naive\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gaussian function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_eq(n, mew, std_div):\n",
    "    return (1/np.sqrt(2*math.pi*std_div))*np.exp(- ((n - mew)**2)  / ( 2*std_div ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the data and calculate all mews and standard deviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = loadTrainingSet()\n",
    "    \n",
    "mews = np.zeros([10,784])\n",
    "standard_div = np.zeros([10,784])\n",
    "for c in range(10):\n",
    "    mew_c = np.zeros(784)\n",
    "    for i in range( c*240 , c*240+240):\n",
    "        mew_c = mew_c + np.true_divide(images[i,:-1],255.0)\n",
    "    mews[c] = np.divide(mew_c,240)\n",
    "\n",
    "\n",
    "for c in range(10):\n",
    "    std_c = np.zeros(784)\n",
    "    for i in range( c*240 , c*240+240):\n",
    "        std_c = std_c + ( pow(np.true_divide(images[i,:-1],255.0) - mews[c],2) )\n",
    "    standard_div[c] = np.true_divide( std_c,240 )\n",
    "\n",
    "standard_div[standard_div<0.01]=0.01\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the data and generate the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_test(filepath, mews, standard_div):\n",
    "    img = plt.imread(filepath)\n",
    "    img2 = img.flatten()\n",
    "    img3 = np.true_divide(img2,255.0)\n",
    "\n",
    "    probs = np.ones(10) \n",
    "    gaussian = gaussian_eq(img3, mews, standard_div)\n",
    "    probs = gaussian\n",
    "    \n",
    "    return np.argmax(np.prod(probs,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kghandour/Library/Python/3.7/lib/python/site-packages/numpy/core/fromnumeric.py:90: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18.  0.  0.  0.  0.  0.  1.  0.  1.  0.]\n",
      " [ 0. 20.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0. 16.  0.  0.  1.  1.  0.  1.  1.]\n",
      " [ 0.  0.  0. 17.  0.  1.  0.  0.  2.  0.]\n",
      " [ 0.  0.  0.  0. 12.  0.  3.  0.  1.  4.]\n",
      " [ 0.  0.  0.  0.  2. 14.  0.  0.  3.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0. 19.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  3.  0.  0. 12.  0.  5.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.  0. 18.  1.]\n",
      " [ 1.  0.  0.  1.  3.  0.  0.  1.  1. 13.]]\n"
     ]
    }
   ],
   "source": [
    "confusionMatrix= np.zeros((10, 10))\n",
    "for i in range(1,201):\n",
    "    testingResult = naive_test('./Test/'+str(i)+'.jpg', mews, standard_div)\n",
    "    confusionMatrix[((i-1)//20), testingResult] += 1\n",
    "\n",
    "print(confusionMatrix)\n",
    "plt.imshow(confusionMatrix)\n",
    "plt.savefig(\"./Confusion-Gauss.jpg\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
